<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
    <!-- ***** -->
    <title>
        Breaking Free: How to Hack Safety Guardrails in Black-Box Diffusion Models!
    </title>
    <meta name="description"
        content="Project page for &#39;Breaking Free: How to Hack Safety Guardrails in Black-Box Diffusion Models!&#39;">
    <!-- ***** -->

    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <style>
        @import url('https://fonts.cdnfonts.com/css/chalkduster');
    </style>

    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="style.css" type="text/css">
    <link rel="stylesheet" href="https://fonts.cdnfonts.com/css/chalkduster" >
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous">

</head>

<body>

    <p class="title">
        Breaking Free: How to Hack Safety Guardrails in Black-Box Diffusion Models!
    </p>

    <div style="text-align: center; font-size: 40pt; margin-bottom: 30px">
            <!-- <span>CVPR 2023</span> -->
    </div>

    <p class="author">
        <span class="author"><a target="_blank" href="https://sites.google.com/site/shashankkotyan">Shashank&nbsp;Kotyan</a>&nbsp;<sup>1*</sup></span>
        <span class="author"><a target="_blank" href="https://scholar.google.co.in/citations?user=R_HEXc0AAAAJ">Po-Yuan&nbsp;Mao</a>&nbsp;<sup>1*</sup></span>
        <span class="author"><a target="_blank" href="http://danilovargas.org/">Danilo&nbsp;Vasconcellos&nbsp;Vargas</a>&nbsp;<sup>1</sup></span>
        <span class="author"><a target="_blank" href="https://sites.google.com/site/pinyuchenpage/home">Pin-Yu&nbsp;Chen</a>&nbsp;<sup>2</sup></span>
    </p>

    <table class="affiliations">
        <tbody>
            <tr>
                <td style="text-align: center; width:0%; "><sup>1</sup>Kyushu University</td>
            </tr>
            <tr>
            	<td style="text-align: center; width:0%; "><sup>2</sup>IBM Research</td>
            </tr>
            <tr></tr>
            <tr>
                <td style="text-align: center; width:0%; "><sup>*</sup>&nbsp;Equal Contribution</td>
            </tr>
            
        </tbody>
    </table>

    <table align="center" class="menu">
        <tbody>
            <tr>
                <td align="center"> 
                    <span class="menu"><a href="https://arxiv.org/abs/2402.04699">[Paper]</a></span>
                    <span class="menu"><a href="https://github.com/shashankkotyan/EvoSeed/">[Code]</a></span>
                    <span class="menu"><a href="./assets/reference.bib">[BibTeX]</a></span>
                </td> 
            </tr>
        </tbody>
    </table>

    <div class="container">
        <br><hr class="hr-twill-colorful"><br>

        <div class="image" style="text-align:center;">
            <img src="./assets/illustration.png" alt="Overview of three distinct basic patterns of k* Distribution." width="60%" style="margin: auto" />
            <figcaption>Figure: Performance of EvoSeed compared to Random Search.</figcaption>
        </div>
        
        <br>

        <strong>Key Contributions:</strong>

        <ul>
            <li> A model-agnostic black-box algorithimic framework based on Evolutionary Strategy to generate unrestricted natural adversarial samples. </li>
            <li> A model-agnostic black-box algorithimic framework based on Evolutionary Strategy to generate unrestricted natural adversarial samples.. </li>
        </ul>

        <br><hr class="hr-twill-colorful"><br>

        <p class="section"><strong>Abstract</strong></p> 
        <p class="text"> 
            Deep neural networks are exploited using natural adversarial samples, which have no impact on human perception but are misclassified.
            Current approaches often rely on the white-box nature of deep neural networks to generate these adversarial samples or alter the distribution of adversarial samples compared to training distribution.
            To alleviate the limitations of current approaches, we propose EvoSeed, a novel evolutionary strategy-based search algorithmic framework to generate natural adversarial samples.
            Our EvoSeed framework uses auxiliary Diffusion and Classifier models to operate in a model-agnostic black-box setting.
            We employ CMA-ES to optimize the search for an adversarial seed vector, which, when processed by the Conditional Diffusion Model, results in an unrestricted natural adversarial sample misclassified by the Classifier Model.
            Experiments show that generated adversarial images are of high image quality and are transferable to different classifiers.
            Our approach demonstrates promise in enhancing the quality of adversarial samples using evolutionary algorithms.
            We hope our research opens new avenues to enhance the robustness of deep neural networks in real-world scenarios. 
        </p>    

        <br><hr class="hr-twill-colorful"><br>

        <p class="section"><strong>Method</strong></p>

        <div class="image">
            <img src="./assets/framework.png" alt="" width="100%"/>
            <figcaption class="caption">Figure: Overview of the Evoseed framework to generate Natural Adversarial Samples. We use auxillary diffusion and classifier models in our framework.</figcaption>
        </div>
        <br>
        
        <br><hr class="hr-twill-colorful"><br>

        <p class="section"><strong>Visualizations of Generated Natural Adversarial Samples </strong></p>

        <div class="image">
            <img src="./assets/compare.png" alt="" width="100%">
            <figcaption> Figure: Visualization of the generated natural adversarial samples by Random Search (RandSeed) and proposed EvoSeed. </figcaption> 
        </div>

        <br><hr class="hr-twill-colorful"><br>

        <p class="section" id="bibtex"><b>Bibtex</b></p>
        <pre class="bibtex">
@article{kotyan2024EvoSeed,
  title = {Breaking Free: How to Hack Safety Guardrails in Black-Box Diffusion Models!,
  author = {Kotyan, Shashank and Mao, Po-Yuan and Vargas, Danilo Vasconcellos, Chen and Pin-Yu},
  year = {2024},
  month = may,
  number = {arXiv:2402.04699},
  eprint = {2402.04699},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2402.04699},
}
        </pre>

    </div>



</body>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.6/dist/umd/popper.min.js" integrity="sha384-oBqDVmMz9ATKxIep9tiCxS/Z9fNfEXiDAYTujMAeBAsjFuCZSmKbSSUnQlmh/jp3" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-kenU1KFdBIe4zVF0s0G1M5b4hcpxyD9F7jL+jjXkk+Q2h455rYXK/7HAuoJl+0I4" crossorigin="anonymous"></script>
</html>
